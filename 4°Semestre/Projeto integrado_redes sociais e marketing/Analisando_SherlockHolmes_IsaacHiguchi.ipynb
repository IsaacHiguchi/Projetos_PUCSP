{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffbcaa2f",
   "metadata": {},
   "source": [
    "# Analisando o livro Moby Dick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c95c2695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://HiguchiNotebook:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>CDIA4-22-BookAnalysis-PySpark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x2b8c9c0fd30>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inicializando uma sessão no PySpark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "          .builder \\\n",
    "          .appName(\"CDIA4-22-BookAnalysis-PySpark\") \\\n",
    "          .getOrCreate()\n",
    "\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4f1312",
   "metadata": {},
   "source": [
    "## Leitura do livro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c6169f49",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------+\n",
      "|                                             value|\n",
      "+--------------------------------------------------+\n",
      "|                                                  |\n",
      "|Project Gutenberg's The Adventures of Sherlock ...|\n",
      "|                                                  |\n",
      "|This eBook is for the use of anyone anywhere at...|\n",
      "|almost no restrictions whatsoever.  You may cop...|\n",
      "|re-use it under the terms of the Project Gutenb...|\n",
      "|    with this eBook or online at www.gutenberg.net|\n",
      "|                                                  |\n",
      "|                                                  |\n",
      "|          Title: The Adventures of Sherlock Holmes|\n",
      "|                                                  |\n",
      "|                        Author: Arthur Conan Doyle|\n",
      "|                                                  |\n",
      "|     Release Date: November 29, 2002 [EBook #1661]|\n",
      "|                        Last Updated: May 20, 2019|\n",
      "|                                                  |\n",
      "|                                 Language: English|\n",
      "|                                                  |\n",
      "|                     Character set encoding: UTF-8|\n",
      "|                                                  |\n",
      "+--------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lendo o arquivo .txt e visualizando-o\n",
    "\n",
    "book = spark.read.text(\"./livros_para_analise/the-adventures-of-sherlock-holmes.txt\")\n",
    "book.show(truncate = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a824c822",
   "metadata": {},
   "source": [
    "## Tokenização"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf525bb7",
   "metadata": {},
   "source": [
    "### Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e3ed659d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------+\n",
      "|                                              line|\n",
      "+--------------------------------------------------+\n",
      "|                                                []|\n",
      "|[Project, Gutenberg's, The, Adventures, of, She...|\n",
      "|                                                []|\n",
      "|[This, eBook, is, for, the, use, of, anyone, an...|\n",
      "|[almost, no, restrictions, whatsoever., , You, ...|\n",
      "|[re-use, it, under, the, terms, of, the, Projec...|\n",
      "|[with, this, eBook, or, online, at, www.gutenbe...|\n",
      "|                                                []|\n",
      "|                                                []|\n",
      "|   [Title:, The, Adventures, of, Sherlock, Holmes]|\n",
      "|                                                []|\n",
      "|                   [Author:, Arthur, Conan, Doyle]|\n",
      "|                                                []|\n",
      "|[Release, Date:, November, 29,, 2002, [EBook, #...|\n",
      "|                  [Last, Updated:, May, 20,, 2019]|\n",
      "|                                                []|\n",
      "|                              [Language:, English]|\n",
      "|                                                []|\n",
      "|                [Character, set, encoding:, UTF-8]|\n",
      "|                                                []|\n",
      "+--------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import split\n",
    "# Separando elementos por \" \"\n",
    "lines = book.select(\n",
    "    split(book.value, \" \").alias(\"line\")\n",
    ")\n",
    "\n",
    "# Visualizando\n",
    "lines.show(truncate=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4c3d25",
   "metadata": {},
   "source": [
    "### Explodindo linhas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e578e102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|       word|\n",
      "+-----------+\n",
      "|           |\n",
      "|    Project|\n",
      "|Gutenberg's|\n",
      "|        The|\n",
      "| Adventures|\n",
      "|         of|\n",
      "|   Sherlock|\n",
      "|    Holmes,|\n",
      "|         by|\n",
      "|     Arthur|\n",
      "|      Conan|\n",
      "|      Doyle|\n",
      "|           |\n",
      "|       This|\n",
      "|      eBook|\n",
      "|         is|\n",
      "|        for|\n",
      "|        the|\n",
      "|        use|\n",
      "|         of|\n",
      "+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Explodindo as linhas (transformando cada elemento das listas que estão nas linhas em uma nova linha deixando cada palavra separada)\n",
    "\n",
    "from pyspark.sql.functions import explode, col\n",
    "\n",
    "words = lines.select(\n",
    "    explode(col(\"line\")).alias(\"word\")\n",
    ")\n",
    "words.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c62863",
   "metadata": {},
   "source": [
    "## Limpando os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1a9980",
   "metadata": {},
   "source": [
    "### Deixando as palavras minúsculas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "78be19e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|lowered_word|\n",
      "+------------+\n",
      "|            |\n",
      "|     project|\n",
      "| gutenberg's|\n",
      "|         the|\n",
      "|  adventures|\n",
      "|          of|\n",
      "|    sherlock|\n",
      "|     holmes,|\n",
      "|          by|\n",
      "|      arthur|\n",
      "|       conan|\n",
      "|       doyle|\n",
      "|            |\n",
      "|        this|\n",
      "|       ebook|\n",
      "+------------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mudar a caixa das palavras para minúsculo\n",
    "\n",
    "from pyspark.sql.functions import lower\n",
    "\n",
    "lowered_words = words.select(\n",
    "    lower(\n",
    "        col(\"word\")\n",
    "    ).alias(\"lowered_word\")\n",
    ")\n",
    "lowered_words.show(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa2894c",
   "metadata": {},
   "source": [
    "### Removendo a pontuação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d0e402da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|cleaned_word|\n",
      "+------------+\n",
      "|            |\n",
      "|     project|\n",
      "|   gutenberg|\n",
      "|         the|\n",
      "|  adventures|\n",
      "|          of|\n",
      "|    sherlock|\n",
      "|      holmes|\n",
      "|          by|\n",
      "|      arthur|\n",
      "|       conan|\n",
      "|       doyle|\n",
      "|            |\n",
      "|        this|\n",
      "|       ebook|\n",
      "|          is|\n",
      "|         for|\n",
      "|         the|\n",
      "|         use|\n",
      "|          of|\n",
      "+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import regexp_extract\n",
    "\n",
    "cleaned_words = lowered_words.select(\n",
    "    regexp_extract(\n",
    "        col(\"lowered_word\"), # Indico a coluna\n",
    "        \"[a-z]+\", # Seleciona somente o que parece uma palavra\n",
    "        0 # 0 significa dar o match em toda expressão regular\n",
    "    ).alias(\"cleaned_word\")\n",
    ")\n",
    "cleaned_words.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e9c0b5",
   "metadata": {},
   "source": [
    "### Removendo valores NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "28222a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|      word|\n",
      "+----------+\n",
      "|   project|\n",
      "| gutenberg|\n",
      "|       the|\n",
      "|adventures|\n",
      "|        of|\n",
      "|  sherlock|\n",
      "|    holmes|\n",
      "|        by|\n",
      "|    arthur|\n",
      "|     conan|\n",
      "|     doyle|\n",
      "|      this|\n",
      "|     ebook|\n",
      "|        is|\n",
      "|       for|\n",
      "|       the|\n",
      "|       use|\n",
      "|        of|\n",
      "|    anyone|\n",
      "|  anywhere|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words_nonull = cleaned_words.where(\n",
    "    col(\"cleaned_word\") != \"\"\n",
    ")\n",
    "words_nonull = words_nonull.select(\n",
    "    col(\"cleaned_word\").alias(\"word\")\n",
    ")\n",
    "words_nonull.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78430ea6",
   "metadata": {},
   "source": [
    "## Contagem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4198330",
   "metadata": {},
   "source": [
    "### Contando a frequência de cada palavra "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7564e5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|        word|count|\n",
      "+------------+-----+\n",
      "|      online|    4|\n",
      "|       still|   80|\n",
      "|       those|   67|\n",
      "|        some|  245|\n",
      "|         few|   77|\n",
      "|      doubts|    5|\n",
      "|       inner|    5|\n",
      "|        hope|   32|\n",
      "|    everyday|    1|\n",
      "|   connected|    7|\n",
      "| requirement|    1|\n",
      "|     flashed|    3|\n",
      "|      travel|    3|\n",
      "|  concluding|    1|\n",
      "|         fog|    2|\n",
      "|      spared|    2|\n",
      "|         art|    5|\n",
      "|accumulation|    1|\n",
      "|      waters|    1|\n",
      "|      poetry|    1|\n",
      "+------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "counts = words_nonull.groupBy(\n",
    "    col(\"word\")\n",
    ").count()\n",
    "counts.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a013f2",
   "metadata": {},
   "source": [
    "### Ordenando a contagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0bcf1a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|word|count|\n",
      "+----+-----+\n",
      "| the| 5805|\n",
      "| and| 3071|\n",
      "|   i| 3029|\n",
      "|  to| 2822|\n",
      "|  of| 2778|\n",
      "|   a| 2683|\n",
      "|  in| 1819|\n",
      "|that| 1757|\n",
      "|  it| 1743|\n",
      "| you| 1565|\n",
      "|  he| 1481|\n",
      "| was| 1411|\n",
      "| his| 1159|\n",
      "|  is| 1146|\n",
      "|  my| 1006|\n",
      "|have|  929|\n",
      "|with|  878|\n",
      "|  as|  862|\n",
      "| had|  830|\n",
      "|  at|  780|\n",
      "+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "counts.orderBy(\n",
    "    col(\"count\"),\n",
    "    ascending=False\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a2d708",
   "metadata": {},
   "source": [
    "## Retomando a limpeza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "80c90783",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|        word|\n",
      "+------------+\n",
      "|   [project]|\n",
      "| [gutenberg]|\n",
      "|       [the]|\n",
      "|[adventures]|\n",
      "|        [of]|\n",
      "|  [sherlock]|\n",
      "|    [holmes]|\n",
      "|        [by]|\n",
      "|    [arthur]|\n",
      "|     [conan]|\n",
      "|     [doyle]|\n",
      "|      [this]|\n",
      "|     [ebook]|\n",
      "|        [is]|\n",
      "|       [for]|\n",
      "|       [the]|\n",
      "|       [use]|\n",
      "|        [of]|\n",
      "|    [anyone]|\n",
      "|  [anywhere]|\n",
      "+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words_lst_df = words_nonull.select(\n",
    "    split(\n",
    "        col(\"word\"),\n",
    "        \" \"\n",
    "    ).alias(\"word\")\n",
    ")\n",
    "words_lst_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a76f80b",
   "metadata": {},
   "source": [
    "### Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cd3204e7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+\n",
      "|        word|  meaningful|\n",
      "+------------+------------+\n",
      "|   [project]|   [project]|\n",
      "| [gutenberg]| [gutenberg]|\n",
      "|       [the]|          []|\n",
      "|[adventures]|[adventures]|\n",
      "|        [of]|          []|\n",
      "|  [sherlock]|  [sherlock]|\n",
      "|    [holmes]|    [holmes]|\n",
      "|        [by]|          []|\n",
      "|    [arthur]|    [arthur]|\n",
      "|     [conan]|     [conan]|\n",
      "|     [doyle]|     [doyle]|\n",
      "|      [this]|          []|\n",
      "|     [ebook]|     [ebook]|\n",
      "|        [is]|          []|\n",
      "|       [for]|          []|\n",
      "|       [the]|          []|\n",
      "|       [use]|       [use]|\n",
      "|        [of]|          []|\n",
      "|    [anyone]|    [anyone]|\n",
      "|  [anywhere]|  [anywhere]|\n",
      "+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Removendo as stop words\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "\n",
    "swr = StopWordsRemover(\n",
    "    inputCol=\"word\",\n",
    "    outputCol=\"meaningful\"\n",
    ")\n",
    "\n",
    "swr_df = swr.transform(words_lst_df)\n",
    "swr_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b71a7b",
   "metadata": {},
   "source": [
    "### Removendo valores NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "43a480f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|meaningful|\n",
      "+----------+\n",
      "|   project|\n",
      "| gutenberg|\n",
      "|      null|\n",
      "|adventures|\n",
      "|      null|\n",
      "|  sherlock|\n",
      "|    holmes|\n",
      "|      null|\n",
      "|    arthur|\n",
      "|     conan|\n",
      "|     doyle|\n",
      "|      null|\n",
      "|     ebook|\n",
      "|      null|\n",
      "|      null|\n",
      "|      null|\n",
      "|       use|\n",
      "|      null|\n",
      "|    anyone|\n",
      "|  anywhere|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Removendo os NULLs\n",
    "meaningful = swr_df.select(\n",
    "    (col(\"meaningful\")[0]).alias(\"meaningful\")\n",
    ")\n",
    "meaningful.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "07e525aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|meaningful|\n",
      "+----------+\n",
      "|   project|\n",
      "| gutenberg|\n",
      "|adventures|\n",
      "|  sherlock|\n",
      "|    holmes|\n",
      "+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filtrar os valores NULLs\n",
    "meaningful_nonull = meaningful.where(\n",
    "    col(\"meaningful\") != \"null\"\n",
    ")\n",
    "meaningful_nonull.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56d153a",
   "metadata": {},
   "source": [
    "### Contando os valores novamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4b945a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|  meaningful|count|\n",
      "+------------+-----+\n",
      "|      online|    4|\n",
      "|       still|   80|\n",
      "|      doubts|    5|\n",
      "|       inner|    5|\n",
      "|        hope|   32|\n",
      "|    everyday|    1|\n",
      "|   connected|    7|\n",
      "| requirement|    1|\n",
      "|     flashed|    3|\n",
      "|      travel|    3|\n",
      "|  concluding|    1|\n",
      "|         fog|    2|\n",
      "|      spared|    2|\n",
      "|         art|    5|\n",
      "|accumulation|    1|\n",
      "|      waters|    1|\n",
      "|      poetry|    1|\n",
      "|    whishing|    1|\n",
      "|       crest|    1|\n",
      "|     implore|    2|\n",
      "+------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words_counts = meaningful_nonull.groupby(\n",
    "    col(\"meaningful\")\n",
    ").count()\n",
    "\n",
    "words_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "72a8cca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|meaningful|count|\n",
      "+----------+-----+\n",
      "|      said|  486|\n",
      "|    holmes|  467|\n",
      "|      upon|  466|\n",
      "|       one|  374|\n",
      "|       man|  303|\n",
      "|        mr|  274|\n",
      "|    little|  269|\n",
      "|       see|  232|\n",
      "|       may|  213|\n",
      "|      well|  199|\n",
      "|        us|  184|\n",
      "|     think|  174|\n",
      "|      know|  171|\n",
      "|     shall|  171|\n",
      "|      must|  171|\n",
      "|      come|  162|\n",
      "|      time|  151|\n",
      "|       two|  148|\n",
      "|      came|  146|\n",
      "|      door|  143|\n",
      "+----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classificação da contagem\n",
    "words_counts = words_counts.orderBy(\n",
    "    col(\"count\"), \n",
    "    ascending=False\n",
    ")\n",
    "words_counts.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e2ec7a",
   "metadata": {},
   "source": [
    "## Análise\n",
    "$Said$ - A palavra \"$said$\" que em português é \"disse\" é a palavra mais utilizada e isso se dá pelo fato do livro ser composto por muitas falas, isso nos demonstra a quantidade de detalhes que livro possui e o aprofundamento do diálogo entre os personagens, podemos concluir isso com base nas grandes resoluções de enigmas que o detetive sherlock holmes é famoso por desvendar e explicar aos demais personagens ao longo da história.\n",
    "\n",
    "$Holmes$ - Holmes é a segunda palavra mais utilizada visto que é a forma mais comum que o personagem principal Sherlock Holmes é chamado.\n",
    "\n",
    "$Upon$ - Já a palavra $upon$ é uma preposição utilizada para dizer \"acerca de\" ou até \"em consequência de\" utilizado nos discursos mas também pode ser utilizada para indicar uma posição ou direção, sendo também muito utilizada nos discursos com esse sentido.\n",
    "\n",
    "$Man$ - A palavra man é muito utilizada devido as descrições de situações em que não se possuem pessoas específicas e também nas descrições de ações dos personagens.\n",
    "\n",
    "$Mr$ - Mr é um pronome de tratamento utilizado exclusivamente para homens na língua inglesa. Isso nos mostra a predominâcia de personagens masculinos no livro nos levando ao contexto em que foi escrito, no Reino Unido do século XIX (19) entre os anos de 1891 e 1892, ou seja, os contos se passam num antigo Reino Unido e retrata inclusive a infame Ku Klux Klan (KKK) no conto “As Cinco Sementes de Laranja”."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
